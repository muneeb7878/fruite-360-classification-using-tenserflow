{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1723ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import Sequential , load_model\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d31b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []  # List to store image and label pairs\n",
    "\n",
    "# List of folder paths\n",
    "folder_paths = [\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_6\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_braeburn_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_crimson_snow_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_golden_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_golden_2\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_golden_3\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_granny_smith_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_hit_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_pink_lady_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_red_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_red_2\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_red_3\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_red_delicios_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_red_yellow_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\apple_rotten_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\cabbage_white_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\carrot_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\cucumber_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\cucumber_3\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\eggplant_violet_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\pear_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\pear_3\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\zucchini_1\",\n",
    "r\"fruits-360-original-size\\fruits-360-original-size\\Training\\zucchini_dark_1\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4363538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the folder paths\n",
    "for i in folder_paths:\n",
    "    folder_name = os.path.basename(i)\n",
    "    \n",
    "    # Iterate over the images in the subdirectory\n",
    "    for file_name in os.listdir(i):\n",
    "        image_path = os.path.join(i, file_name)\n",
    "        \n",
    "        if os.path.isfile(image_path):  # Only consider files\n",
    "            # Load the image using OpenCV\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # If the image was successfully loaded\n",
    "            if image is not None:\n",
    "                # Resize the grayscale image to 250X250 pixels\n",
    "                resized_image = cv2.resize(image, (250, 250))\n",
    "                \n",
    "                # Flatten the image and append each pixel as a separate feature along with the label to the dataset\n",
    "                flattened_image = resized_image.flatten().tolist()\n",
    "                dataset.append(flattened_image + [folder_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c506711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>pixel_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_62492</th>\n",
       "      <th>pixel_62493</th>\n",
       "      <th>pixel_62494</th>\n",
       "      <th>pixel_62495</th>\n",
       "      <th>pixel_62496</th>\n",
       "      <th>pixel_62497</th>\n",
       "      <th>pixel_62498</th>\n",
       "      <th>pixel_62499</th>\n",
       "      <th>pixel_62500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>apple_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>apple_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>apple_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>apple_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>apple_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>zucchini_dark_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>zucchini_dark_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>zucchini_dark_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>zucchini_dark_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>zucchini_dark_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6231 rows × 62501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  pixel_8  \\\n",
       "0         255      255      255      255      255      255      255      255   \n",
       "1         255      255      255      255      255      255      255      255   \n",
       "2         255      255      255      255      255      255      255      255   \n",
       "3         255      255      255      255      255      255      255      255   \n",
       "4         255      255      255      255      255      255      255      255   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "6226      255      255      255      255      255      255      255      255   \n",
       "6227      255      255      255      255      255      255      255      255   \n",
       "6228      255      255      255      255      255      255      255      255   \n",
       "6229      255      255      255      255      255      255      255      255   \n",
       "6230      255      255      255      255      255      255      255      255   \n",
       "\n",
       "      pixel_9  pixel_10  ...  pixel_62492  pixel_62493  pixel_62494  \\\n",
       "0         255       255  ...          255          255          255   \n",
       "1         255       255  ...          255          255          255   \n",
       "2         255       255  ...          255          255          255   \n",
       "3         255       255  ...          255          255          255   \n",
       "4         255       255  ...          255          255          255   \n",
       "...       ...       ...  ...          ...          ...          ...   \n",
       "6226      255       255  ...          255          255          255   \n",
       "6227      255       255  ...          255          255          255   \n",
       "6228      255       255  ...          255          255          255   \n",
       "6229      255       255  ...          255          255          255   \n",
       "6230      255       255  ...          255          255          255   \n",
       "\n",
       "      pixel_62495  pixel_62496  pixel_62497  pixel_62498  pixel_62499  \\\n",
       "0             255          255          255          255          255   \n",
       "1             255          255          255          255          255   \n",
       "2             255          255          255          255          255   \n",
       "3             255          255          255          255          255   \n",
       "4             255          255          255          255          255   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "6226          255          255          255          255          255   \n",
       "6227          255          255          255          255          255   \n",
       "6228          255          255          255          255          255   \n",
       "6229          255          255          255          255          255   \n",
       "6230          255          255          255          255          255   \n",
       "\n",
       "      pixel_62500            label  \n",
       "0             255          apple_6  \n",
       "1             255          apple_6  \n",
       "2             255          apple_6  \n",
       "3             255          apple_6  \n",
       "4             255          apple_6  \n",
       "...           ...              ...  \n",
       "6226          255  zucchini_dark_1  \n",
       "6227          255  zucchini_dark_1  \n",
       "6228          255  zucchini_dark_1  \n",
       "6229          255  zucchini_dark_1  \n",
       "6230          255  zucchini_dark_1  \n",
       "\n",
       "[6231 rows x 62501 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Convert the dataset to a pandas DataFrame\"\"\"\n",
    "df = pd.DataFrame(dataset, columns=[f'pixel_{i+1}' for i in range(250*250)] + ['label'])\n",
    "\n",
    "\"\"\"Print the DataFrame\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e26651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values between 0 and 1\n",
    "X = df.iloc[:, :-1] / 255\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "# Encode the labels with numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)\n",
    "y_series = pd.Series(Y_encoded, name='Target')\n",
    "\n",
    "# Concatenate 'X' (features) and 'y_series' (target variable) along columns (axis=1)\n",
    "df_encoded = pd.concat([X, y_series], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_series, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d34cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               8000128   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8009944 (30.56 MB)\n",
      "Trainable params: 8009944 (30.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a dense layer with 128 units and 'relu' activation function as the input layer\n",
    "model.add(Dense(128, activation='relu', input_shape=(250*250,)))\n",
    "\n",
    "# Add another dense layer with 64 units and 'relu' activation function\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer with the number of classes (number of unique labels) and 'softmax' activation function\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model with 'categorical_crossentropy' loss function and 'adam' optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aae518ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 43s 330ms/step - loss: 5.6799 - accuracy: 0.1721 - val_loss: 2.3670 - val_accuracy: 0.2839\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 1.8047 - accuracy: 0.4424 - val_loss: 1.3292 - val_accuracy: 0.5446\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.9097 - accuracy: 0.7033 - val_loss: 0.7274 - val_accuracy: 0.7432\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 16s 132ms/step - loss: 0.5545 - accuracy: 0.8101 - val_loss: 0.3421 - val_accuracy: 0.8947\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.3510 - accuracy: 0.8816 - val_loss: 0.3236 - val_accuracy: 0.8746\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4052 - accuracy: 0.8623 - val_loss: 0.1891 - val_accuracy: 0.9348\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 16s 132ms/step - loss: 0.2042 - accuracy: 0.9298 - val_loss: 0.1268 - val_accuracy: 0.9649\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.1752 - accuracy: 0.9436 - val_loss: 0.1746 - val_accuracy: 0.9488\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.1642 - accuracy: 0.9426 - val_loss: 0.6378 - val_accuracy: 0.7844\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 21s 166ms/step - loss: 0.1345 - accuracy: 0.9539 - val_loss: 0.0820 - val_accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "# Convert target variables to one-hot encoded format for multi-class classification\n",
    "from keras.utils import to_categorical\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "# Train the model on the training data\n",
    "history = model.fit(X_train, y_train_encoded, batch_size=32, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f0d14c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 16ms/step\n",
      "Accuracy: 0.9823576583801122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        75\n",
      "           1       1.00      1.00      1.00        78\n",
      "           2       0.96      1.00      0.98        51\n",
      "           3       1.00      0.82      0.90        73\n",
      "           4       0.96      1.00      0.98        67\n",
      "           5       0.89      0.97      0.93        59\n",
      "           6       0.97      0.97      0.97        63\n",
      "           7       1.00      0.99      1.00       101\n",
      "           8       1.00      1.00      1.00        57\n",
      "           9       1.00      0.98      0.99        59\n",
      "          10       0.98      1.00      0.99        55\n",
      "          11       1.00      1.00      1.00        57\n",
      "          12       0.98      1.00      0.99        59\n",
      "          13       0.90      1.00      0.95        56\n",
      "          14       1.00      0.97      0.98        62\n",
      "          15       1.00      1.00      1.00        20\n",
      "          16       1.00      1.00      1.00        23\n",
      "          17       1.00      1.00      1.00        18\n",
      "          18       1.00      1.00      1.00        38\n",
      "          19       1.00      1.00      1.00        25\n",
      "          20       1.00      0.98      0.99        51\n",
      "          21       1.00      1.00      1.00        33\n",
      "          22       1.00      1.00      1.00        33\n",
      "          23       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           0.98      1247\n",
      "   macro avg       0.99      0.99      0.99      1247\n",
      "weighted avg       0.98      0.98      0.98      1247\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 75   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0  51   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0  60   3   5   0   0   0   0   0   0   0   5   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0  67   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  57   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1  61   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 100   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  57   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  58   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  55   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  57   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  59   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  56   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   0   0   0   0   0  60   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  20   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   38   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  25   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  50   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  33   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  33   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0  34]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred_encoded = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed72f7e",
   "metadata": {},
   "source": [
    "# deployement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecbb6977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HS TRADER\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "model.save('dnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f59dc8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predicted Class: apple_pink_lady_1\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = load_model('dnn_model.h5')\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        # Resize the grayscale image to 250X250 pixels\n",
    "        resized_image = cv2.resize(image, (250, 250))\n",
    "        # Flatten the image\n",
    "        flattened_image = resized_image.flatten() / 255.0\n",
    "        return flattened_image\n",
    "    return None\n",
    "\n",
    "# Provide the image path for prediction\n",
    "image_path = r\"fruits-360-original-size\\fruits-360-original-size\\Test\\apple_pink_lady_1\\r0_67.jpg\"\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "if preprocessed_image is not None:\n",
    "    # Reshape the image to match the model's input shape\n",
    "    preprocessed_image = preprocessed_image.reshape(1, -1)\n",
    "    # Make the prediction\n",
    "    prediction_encoded = model.predict(preprocessed_image)\n",
    "    predicted_class_index = np.argmax(prediction_encoded)\n",
    "    # Convert the encoded label back to the original class label\n",
    "    predicted_class_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "    print(\"Predicted Class:\", predicted_class_label)\n",
    "else:\n",
    "    print(\"Error: Image not found or cannot be processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d013e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
